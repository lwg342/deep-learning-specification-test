{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"colab":{"name":"simulation_repeat.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjDignVIfKyZ","executionInfo":{"status":"ok","timestamp":1620301370715,"user_tz":-60,"elapsed":798,"user":{"displayName":"W. Liu","photoUrl":"","userId":"12224771869776414687"}},"outputId":"94f0c92e-bde6-404d-c50d-7e07febb89c2"},"source":["import sys\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","sys.path.append(\n","    \"/content/drive/My Drive/Colab Notebooks/deep-learning-specification-test\")\n","sys.path.append(\"/content/drive/My Drive/Colab Notebooks/python-functions\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nQK8l8v3fKyf","executionInfo":{"status":"ok","timestamp":1620301411603,"user_tz":-60,"elapsed":1144,"user":{"displayName":"W. Liu","photoUrl":"","userId":"12224771869776414687"}}},"source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import utils \n","from importlib import reload  \n","reload(utils)\n","import time\n","\n","N = 200\n","num_repeat = 20000\n","\n","def true_output(x):\n","    # y = x1.pow(2) + 2* torch.sin(x2) + x1*x2 + x3 * x4\n","    y = x[:,0] + 2* x[:,1] + 3 * x[:,2] + 4*x[:,3]\n","    return y\n","\n","\n","class Net(nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","        self.f1 = nn.Linear(4, 5)\n","        self.f2 = nn.Linear(5, 5)\n","        self.f3 = nn.Linear(5, 5)\n","        self.f4 = nn.Linear(5, 5)\n","        self.predict = nn.Linear(5, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.f1(x))\n","        x = F.relu(self.f2(x))\n","        x = F.relu(self.f3(x))\n","        x = F.relu(self.f4(x))\n","        out = self.predict(x)\n","        return out\n","\n","\n","def repeat(j):\n","    start = time.time()\n","    x = torch.normal(0,1,size = [N,4])\n","    e = 0.2*torch.randn(N)\n","    y = (true_output(x) + e).unsqueeze(-1).float()\n","\n","    net = Net()\n","    \n","    if torch.cuda.is_available():\n","        x = x.cuda(0)\n","        y = y.cuda(0)\n","        net = net.cuda()\n","\n","    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n","    loss_func = torch.nn.MSELoss()  \n","    \n","    for t in range(num_repeat):\n","\n","        prediction = net(x)     # input x and predict based on x\n","        loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n","        optimizer.zero_grad()   # clear gradients for next train\n","        loss.backward()         # backpropagation, compute gradients\n","        optimizer.step()        # apply gradients\n","\n","    optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n","    loss_func = torch.nn.MSELoss()\n","\n","    for t in range(num_repeat):\n","\n","        prediction = net(x)     # input x and predict based on x\n","        loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n","        optimizer.zero_grad()   # clear gradients for next train\n","        loss.backward()         # backpropagation, compute gradients\n","        optimizer.step()        # apply gradients\n","\n","        if t == num_repeat-1:\n","            print(loss)\n","\n","\n","    # Test the Escanciano method\n","    \n","    if torch.cuda.is_available():\n","        y = y.cpu()\n","        z = net(x).cpu()\n","\n","    from wl_regression import OLS  \n","    z0 = OLS(x.numpy(), y.numpy()).y_hat()\n","    e0 = (z0 - y.detach().numpy()[:,0])\n","\n","    z = net(x)\n","    e1 = (z-y).detach().numpy()\n","\n","    # from wl_regression import loc_poly\n","    # ll_z = loc_poly(y.numpy(), x.numpy(), x.detach().numpy())\n","    # e2 = (ll_z - y.detach().numpy()[:,0])\n","\n","    C_resid = utils.C_resid\n","    C = C_resid(e0, e1, e0, N)\n","    # print(C)\n","\n","    test_statistic = utils.test_statistic\n","    sigma_hat = utils.compute_w(x, y, e0, e1, N)[1]\n","    rslt = test_statistic(C, N, sigma_hat)\n","\n","    end = time.time()\n","    print(f\"{j}-th iter in time {end - start}\")\n","    return rslt"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLJTC3N6fKyh"},"source":["import pickle\n","from google.colab import files\n","\n","rslt_repeat = [repeat(j) for j in range(100)]\n","\n","i = time.strftime(\"%Y%m%d%H\")\n","with open(f\"result-{i}.p\", mode = 'wb') as f:\n","  pickle.dump(rslt_repeat, f)\n","\n","files.download(f'result-{i}.p')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q9x0yiFIfPZY"},"source":[""],"execution_count":null,"outputs":[]}]}